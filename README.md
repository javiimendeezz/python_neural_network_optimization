# Optimización de Redes Neuronales

Este proyecto tiene como objetivo optimizar redes neuronales mediante diferentes técnicas de ajuste de hiperparámetros y estructuras, utilizando un enfoque basado en notebooks para experimentar con diversas configuraciones. Se enfoca en mejorar la precisión y eficiencia de modelos aplicados a problemas específicos de aprendizaje automático.

---

## Características principales

- **Optimización de hiperparámetros**: incluye la exploración de arquitecturas de redes neuronales, funciones de activación, y tasas de aprendizaje.
- **Uso de librerías avanzadas**: emplea TensorFlow/Keras o PyTorch para la creación y ajuste de modelos.
- **Análisis de rendimiento**: incluye métricas como pérdida, precisión, y gráficos de entrenamiento/validación.
- **Visualización de resultados**: se generan gráficos para analizar el impacto de los cambios en los hiperparámetros.

---

## Requisitos

Asegúrate de que tienes instalado lo siguiente:

- Python 3.8 o superior
- Librerías necesarias (instalar con el comando `pip install -r requirements.txt`):
  - TensorFlow o PyTorch
  - NumPy
  - Matplotlib
  - scikit-learn

---



## Cómo usar este proyecto

1. **Clona el repositorio**:
   ```bash
   git clone <URL-del-repositorio>
   cd <nombre-del-repositorio>
   ```

2. **Ejecuta el notebook**:
   Abre `nn_opt.ipynb` en Jupyter Notebook o JupyterLab y sigue las instrucciones para ejecutar los experimentos.



---

## Próximos pasos

- Implementar técnicas avanzadas de regularización como Dropout y Batch Normalization.
- Explorar optimizadores adicionales como AdamW y RAdam.
- Realizar experimentos con redes neuronales profundas y modelos recurrentes.

---

## Contribuciones

Las contribuciones son bienvenidas. Si encuentras un problema o tienes una idea para mejorar este proyecto, por favor, abre un issue o envía un pull request.

---

## Autor

Creado por **Javier Méndez**. Estudiante apasionado/a por la intersección entre la informática y la ciencia de datos.


